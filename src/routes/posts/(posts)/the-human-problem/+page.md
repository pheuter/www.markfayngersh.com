<svelte:head>

<title>Mark Fayngersh | The Human Problem</title>
<meta name="description" content="In order for society to truly embrace the challenge of building AI systems that are aligned with our goals and values, we must first reckon with perennial questions about human morality and ethics." />
<meta name="author" content="Mark Fayngersh" />

</svelte:head>

# The Human Problem

In order for society to truly embrace the challenge of building AI systems that are aligned with our goals and values, we must first reckon with perennial questions about human morality and ethics.

## A Retrospective

Tremendous progress has been made in the last three years since I initially wrote about GPT-3's early hints at sophistication, though not without an accompanying stream of conceptual roadblocks. Some of the greatest intellectuals and skeptics have felt compelled to [confront](https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html) (_Noam Chomsky: The False Promise of ChatGPT_) the growing capabilities of generative AI, recycling arguments that boil down to a disagreement around what exactly we mean by ["thinking"](/posts/the-thinking-placebo). That NYT opinion piece was published just a few days before OpenAI announced their significantly more capable GPT-4 modelâ€”some of the article's intuitions haven't aged well, perhaps unsurprisingly.

Let's revisit one of the examples put forth by Dr. Watumull designed to elicit moral insights, **"Would it be moral to terraform Mars?"**.

Here is the original response quoted in the article that was produced by earlier versions of ChatGPT:

> The morality of terraforming Mars is a complex and controversial topic that has been debated by scientists, philosophers, and ethicists. Some argue that it would be morally justifiable to terraform Mars in order to provide a new habitable environment for humans and other life forms, while others argue that it would be morally wrong to fundamentally alter the planet's natural state. Ultimately, whether or not terraforming Mars is considered moral would depend on one's perspective on the value of preserving the natural state of other planets and the potential consequences of altering them.

And [here](https://chat.openai.com/share/76ea1e6d-c467-4df8-9be8-77a37c6c87db) is a response from GPT-4:

> The question of the morality of terraforming Mars hinges on various ethical, philosophical, and practical considerations. Here are a few of the major viewpoints to consider:
>
> 1. Expanding Human Civilization: From a utilitarian perspective, if Earth becomes overpopulated or faces a global catastrophe, colonizing and terraforming Mars could ensure the survival of the human species. In this view, the greater good is seen in preserving and propagating human life, which could be considered morally correct.
> 2. Preservation of Native Martian Environment: Some ethicists argue that Mars, like other planets, has an inherent right to its existing conditions and should be left untouched. Terraforming could potentially destroy evidence of past or present extraterrestrial life, which would be an invaluable scientific resource. Terraforming could also irrevocably change Martian geology and meteorology, which could be seen as a form of cosmic vandalism.
> 3. Planetary Protection and Ethic of Care: The ethic of care standpoint takes into account our responsibility to ensure that our activities do not harm other life forms or ecosystems. This would mean ensuring that any life forms, even potential microbial life on Mars, are not negatively affected by terraforming efforts.
> 4. Anthropocentric Vs Biocentric Ethics: If one holds a purely anthropocentric ethical view (human-centered), they may believe that humans have the right to modify environments for their benefit. In contrast, a biocentric view (life-centered) would argue that all life has an intrinsic value, which should be respected and preserved.
> 5. The Precautionary Principle: This principle suggests that we should avoid actions that could lead to potentially serious or irreversible harm, particularly when the outcomes are uncertain. As we don't yet fully understand the potential impacts of terraforming Mars, following this principle might lead us to refrain from terraforming.
> 6. The Inevitability of Progress: Some argue that human progress and exploration are inevitable aspects of our nature. From this perspective, if we have the ability to terraform Mars, it may be seen as the next step in human evolution and expansion.
>
> The question of terraforming Mars is not simply a matter of can we, but should we. The answer to that question depends heavily on one's ethical framework and values. It also depends on the future discoveries about Mars, such as the potential existence of life there. Further exploration and understanding of the Martian environment will undoubtedly inform these debates.

Looking back, the conclusion reached in the article referring to AI like ChatGPT that _"we can only laugh or cry at their popularity"_ as made evident by _"the moral indifference born of unintelligence"_ may have been somewhat premature.

Still, the article makes some valid points that can't be easily dismissed. Counterfactual reasoning and intuitions about causality are fundamental components of human experience, and it remains unclear to what degree transformer-based models are capable of interpreting and reasoning about reality like we do.
